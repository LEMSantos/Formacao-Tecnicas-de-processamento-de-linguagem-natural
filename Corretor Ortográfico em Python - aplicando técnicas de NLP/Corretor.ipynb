{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87d592f0-e543-469a-becb-d9024b433b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b51e1593-8ba1-4101-bbcb-d72b2e56f78b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nimagem \\n\\ntemos a seguinte classe que representa um usuário no nosso sistema:\\n\\njava\\n\\npara salvar um novo usuário, várias validações são feitas, como por exemplo: ver se o nome só contém letras, [**o cpf só números**] e ver se o usuário possui no mínimo 18 anos. veja o método que faz essa validação:\\n\\njava \\n\\nsuponha agora que eu tenha outra classe, a classe `produto`, que contém um atributo nome e eu quero fazer a mesma validação que fiz para o nome do usuário: ver se só contém letras. e aí? vou'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/artigos.txt', 'r') as _file:\n",
    "    corpus = _file.read().lower()\n",
    "    \n",
    "corpus[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9192145-677f-4328-a08a-9be8e153a339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "punctuation_list = ''.join(list(punctuation))\n",
    "punctuation_translator = str.maketrans('', '', punctuation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "527126be-f014-47fc-b73d-2b00c8166056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nimagem \\n\\ntemos a seguinte classe que representa um usuário no nosso sistema\\n\\njava\\n\\npara salvar um novo usuário várias validações são feitas como por exemplo ver se o nome só contém letras o cpf só números e ver se o usuário possui no mínimo 18 anos veja o método que faz essa validação\\n\\njava \\n\\nsuponha agora que eu tenha outra classe a classe produto que contém um atributo nome e eu quero fazer a mesma validação que fiz para o nome do usuário ver se só contém letras e aí vou criar outro método '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_v1 = corpus.translate(punctuation_translator)\n",
    "corpus_v1[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "019fd07d-496d-4200-b7af-4eaa308059b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imagem', 'temos', 'a', 'seguinte', 'classe', 'que', 'representa', 'um', 'usuário', 'no', 'nosso', 'sistema', 'java', 'para', 'salvar', 'um', 'novo', 'usuário', 'várias', 'validações', 'são', 'feitas', 'como', 'por', 'exemplo', 'ver', 'se', 'o', 'nome', 'só', 'contém', 'letras', 'o', 'cpf', 'só', 'números', 'e', 'ver', 'se', 'o', 'usuário', 'possui', 'no', 'mínimo', '18', 'anos', 'veja', 'o', 'método', 'que', 'faz', 'essa', 'validação', 'java', 'suponha', 'agora', 'que', 'eu', 'tenha', 'outra', 'classe', 'a', 'classe', 'produto', 'que', 'contém', 'um', 'atributo', 'nome', 'e', 'eu', 'quero', 'fazer', 'a', 'mesma', 'validação', 'que', 'fiz', 'para', 'o', 'nome', 'do', 'usuário', 'ver', 'se', 'só', 'contém', 'letras', 'e', 'aí', 'vou', 'criar', 'outro', 'método', 'para', 'fazer', 'a', 'mesma', 'validação', 'ou']\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.tokenize.word_tokenize(corpus_v1)\n",
    "print(tokens[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20c17943-0a8f-4ee1-a0fd-f51e3caa5067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imagem', 'temos', 'a', 'seguinte', 'classe', 'que', 'representa', 'um', 'usuário', 'no', 'nosso', 'sistema', 'java', 'para', 'salvar', 'um', 'novo', 'usuário', 'várias', 'validações', 'são', 'feitas', 'como', 'por', 'exemplo', 'ver', 'se', 'o', 'nome', 'só', 'contém', 'letras', 'o', 'cpf', 'só', 'números', 'e', 'ver', 'se', 'o', 'usuário', 'possui', 'no', 'mínimo', 'anos', 'veja', 'o', 'método', 'que', 'faz', 'essa', 'validação', 'java', 'suponha', 'agora', 'que', 'eu', 'tenha', 'outra', 'classe', 'a', 'classe', 'produto', 'que', 'contém', 'um', 'atributo', 'nome', 'e', 'eu', 'quero', 'fazer', 'a', 'mesma', 'validação', 'que', 'fiz', 'para', 'o', 'nome', 'do', 'usuário', 'ver', 'se', 'só', 'contém', 'letras', 'e', 'aí', 'vou', 'criar', 'outro', 'método', 'para', 'fazer', 'a', 'mesma', 'validação', 'ou', 'criar']\n"
     ]
    }
   ],
   "source": [
    "tokens_v1 = list(filter(str.isalpha, tokens))\n",
    "print(tokens_v1[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7b4bed1-4227-499d-9496-dc3a92523af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "406583"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87cb3c56-6dc7-4d13-887b-385fb7becec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "knowledge = Counter(tokens_v1)\n",
    "total_knowledge = knowledge.total()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7500cd3d-57b2-4dff-b669-9f07947b5ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_by_insert(word):\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    \n",
    "    return [\n",
    "        word[:pos] + letter + word[pos:]\n",
    "        for letter in letters\n",
    "        for pos in range(len(word) + 1)\n",
    "    ]\n",
    "\n",
    "\n",
    "def generate_by_delete(word):\n",
    "    return [\n",
    "        word[:pos] + word[pos + 1:]\n",
    "        for pos in range(len(word) + 1)\n",
    "    ]\n",
    "\n",
    "\n",
    "def generate_by_swap(word):\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    \n",
    "    return [\n",
    "        word[:pos] + letter + word[pos + 1:]\n",
    "        for letter in letters\n",
    "        for pos in range(len(word) + 1)\n",
    "    ]\n",
    "\n",
    "\n",
    "def generate_by_exchange(word):\n",
    "    return [\n",
    "        word[:pos] + word[pos + 1] + word[pos] + word[pos + 2:]\n",
    "        for pos in range(len(word) - 1)\n",
    "    ]\n",
    "\n",
    "\n",
    "def words_generator_1_dist(word):\n",
    "    generated_words = [\n",
    "        *generate_by_insert(word),\n",
    "        *generate_by_delete(word),\n",
    "        *generate_by_swap(word),\n",
    "        *generate_by_exchange(word),\n",
    "    ]\n",
    "    \n",
    "    return generated_words\n",
    "\n",
    "\n",
    "def words_generator_2_dist(generated_words):\n",
    "    generated_words_2_dist = []\n",
    "\n",
    "    for word in generated_words:\n",
    "        generated_words_2_dist += words_generator_1_dist(word)\n",
    "    \n",
    "    return generated_words_2_dist\n",
    "\n",
    "\n",
    "def get_probability(word):\n",
    "    return knowledge[word] / total_knowledge\n",
    "\n",
    "\n",
    "def corrector_v1(word):\n",
    "    generated_words = words_generator_1_dist(word)\n",
    "    return max(generated_words, key=get_probability)\n",
    "\n",
    "\n",
    "def corrector_v2(word):\n",
    "    generated_words = words_generator_1_dist(word)\n",
    "    generated_words += words_generator_2_dist(generated_words)\n",
    "    candidates = [word for word in generated_words if word in knowledge]\n",
    "\n",
    "    if len(candidates):\n",
    "        correct_word = max(candidates, key=get_probability)\n",
    "        return correct_word\n",
    "    \n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59c93301-dbf4-446b-b2c6-48729585c7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(model, X, Y):\n",
    "    corrected_words = np.array(list(map(lambda x: model(x), X)))\n",
    "    return '%.2f%%' % (np.sum(corrected_words == Y) * 100 / X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38c6f78c-bddc-4e1b-83d1-91efbc2a96a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['podemos', 'pyodemos'],\n",
       "       ['esse', 'esje'],\n",
       "       ['já', 'jrá'],\n",
       "       ['nosso', 'nossov'],\n",
       "       ['são', 'sãêo'],\n",
       "       ['dos', 'dosa'],\n",
       "       ['muito', 'muifo'],\n",
       "       ['imagem', 'iômagem'],\n",
       "       ['sua', 'ósua'],\n",
       "       ['também', 'tambéùm']], dtype='<U13')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/palavras.txt', 'r') as _file:\n",
    "    test_data = _file.readlines()\n",
    "    \n",
    "test_data = np.array([line.strip().split() for line in test_data])\n",
    "test_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c39bf3d-5c0d-4088-9d0b-cd9137eb04e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data[:, 1]\n",
    "Y_test = test_data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8636f73c-351c-4f16-b0d0-53a70f31e832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.34%\n",
      "54.84%\n"
     ]
    }
   ],
   "source": [
    "print(score(corrector_v1, X_test, Y_test))\n",
    "print(score(corrector_v2, X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db98fe63-964a-4247-8dc0-5e40a1347b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.99%\n"
     ]
    }
   ],
   "source": [
    "unknown_words = [true_word not in knowledge for true_word in Y_test]\n",
    "print('%.2f%%' % (sum(unknown_words) * 100 / len(Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364c4c5d-1e04-4468-bc00-7752da22e943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
